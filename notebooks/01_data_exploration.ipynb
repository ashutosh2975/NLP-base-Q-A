{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaeddcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup successful\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keybert import KeyBERT\n",
    "\n",
    "print(\"Environment setup successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be6258b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to C:\\Users\\ashut\\.cache\\kagglehub\\datasets\\stackoverflow\\stacksample\\2.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.11G/1.11G [09:30<00:00, 2.09MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ashut\\.cache\\kagglehub\\datasets\\stackoverflow\\stacksample\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"stackoverflow/stacksample\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9590c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions: (1264216, 7)\n",
      "Answers: (2014516, 6)\n",
      "Tags: (3750994, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATASET_PATH = \"C:/Users/ashut/.cache/kagglehub/datasets/stackoverflow/stacksample/versions/2\"\n",
    "\n",
    "questions = pd.read_csv(\n",
    "    os.path.join(DATASET_PATH, \"Questions.csv\"),\n",
    "    encoding=\"latin1\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "answers = pd.read_csv(\n",
    "    os.path.join(DATASET_PATH, \"Answers.csv\"),\n",
    "    encoding=\"latin1\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "tags = pd.read_csv(\n",
    "    os.path.join(DATASET_PATH, \"Tags.csv\"),\n",
    "    encoding=\"latin1\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "print(\"Questions:\", questions.shape)\n",
    "print(\"Answers:\", answers.shape)\n",
    "print(\"Tags:\", tags.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "851071aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'OwnerUserId', 'CreationDate', 'ParentId', 'Score', 'Body'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answers table structure check\n",
    "answers.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde1bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group tags per question\n",
    "tag_list = tags.groupby(\"Id\")[\"Tag\"].apply(list).reset_index()\n",
    "tag_list.rename(columns={\"Tag\": \"Tags_List\"}, inplace=True)\n",
    "\n",
    "# Merge with questions\n",
    "questions = questions.merge(tag_list, on=\"Id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f51ab7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>Answers_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>[&lt;p&gt;I wound up using this. It is a kind of a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>[&lt;p&gt;&lt;a href=\"http://svnbook.red-bean.com/\"&gt;Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>[&lt;p&gt;The Jeff Prosise version from MSDN magazin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>[&lt;p&gt;I've read somewhere the human eye can't di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>[&lt;p&gt;Yes, I thought about that, but I soon figu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId                                       Answers_List\n",
       "0          80  [<p>I wound up using this. It is a kind of a h...\n",
       "1          90  [<p><a href=\"http://svnbook.red-bean.com/\">Ver...\n",
       "2         120  [<p>The Jeff Prosise version from MSDN magazin...\n",
       "3         180  [<p>I've read somewhere the human eye can't di...\n",
       "4         260  [<p>Yes, I thought about that, but I soon figu..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group answers by QUESTION ID (ParentId)\n",
    "answers_grouped = (\n",
    "    answers\n",
    "    .groupby(\"ParentId\")[\"Body\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename properly\n",
    "answers_grouped.rename(\n",
    "    columns={\n",
    "        \"ParentId\": \"QuestionId\",\n",
    "        \"Body\": \"Answers_List\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "answers_grouped.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db0ab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags_List</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>Answers_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2008-08-01T13:57:07Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>SQLStatement.execute() - multiple queries in o...</td>\n",
       "      <td>&lt;p&gt;I've written a database generation script i...</td>\n",
       "      <td>[flex, actionscript-3, air]</td>\n",
       "      <td>80.0</td>\n",
       "      <td>[&lt;p&gt;I wound up using this. It is a kind of a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2008-08-01T14:41:24Z</td>\n",
       "      <td>2012-12-26T03:45:49Z</td>\n",
       "      <td>144</td>\n",
       "      <td>Good branching and merging tutorials for Torto...</td>\n",
       "      <td>&lt;p&gt;Are there any really good tutorials explain...</td>\n",
       "      <td>[svn, tortoisesvn, branch, branching-and-merging]</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[&lt;p&gt;&lt;a href=\"http://svnbook.red-bean.com/\"&gt;Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2008-08-01T15:50:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>&lt;p&gt;Has anyone got experience creating &lt;strong&gt;...</td>\n",
       "      <td>[sql, asp.net, sitemap]</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[&lt;p&gt;The Jeff Prosise version from MSDN magazin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>2089740.0</td>\n",
       "      <td>2008-08-01T18:42:19Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Function for creating color wheels</td>\n",
       "      <td>&lt;p&gt;This is something I've pseudo-solved many t...</td>\n",
       "      <td>[algorithm, language-agnostic, colors, color-s...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>[&lt;p&gt;I've read somewhere the human eye can't di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2008-08-01T23:22:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>&lt;p&gt;I have a little game written in C#. It uses...</td>\n",
       "      <td>[c#, .net, scripting, compiler-construction]</td>\n",
       "      <td>260.0</td>\n",
       "      <td>[&lt;p&gt;Yes, I thought about that, but I soon figu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  OwnerUserId          CreationDate            ClosedDate  Score  \\\n",
       "0   80         26.0  2008-08-01T13:57:07Z                   NaN     26   \n",
       "1   90         58.0  2008-08-01T14:41:24Z  2012-12-26T03:45:49Z    144   \n",
       "2  120         83.0  2008-08-01T15:50:08Z                   NaN     21   \n",
       "3  180    2089740.0  2008-08-01T18:42:19Z                   NaN     53   \n",
       "4  260         91.0  2008-08-01T23:22:08Z                   NaN     49   \n",
       "\n",
       "                                               Title  \\\n",
       "0  SQLStatement.execute() - multiple queries in o...   \n",
       "1  Good branching and merging tutorials for Torto...   \n",
       "2                                  ASP.NET Site Maps   \n",
       "3                 Function for creating color wheels   \n",
       "4  Adding scripting functionality to .NET applica...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I've written a database generation script i...   \n",
       "1  <p>Are there any really good tutorials explain...   \n",
       "2  <p>Has anyone got experience creating <strong>...   \n",
       "3  <p>This is something I've pseudo-solved many t...   \n",
       "4  <p>I have a little game written in C#. It uses...   \n",
       "\n",
       "                                           Tags_List  QuestionId  \\\n",
       "0                        [flex, actionscript-3, air]        80.0   \n",
       "1  [svn, tortoisesvn, branch, branching-and-merging]        90.0   \n",
       "2                            [sql, asp.net, sitemap]       120.0   \n",
       "3  [algorithm, language-agnostic, colors, color-s...       180.0   \n",
       "4       [c#, .net, scripting, compiler-construction]       260.0   \n",
       "\n",
       "                                        Answers_List  \n",
       "0  [<p>I wound up using this. It is a kind of a h...  \n",
       "1  [<p><a href=\"http://svnbook.red-bean.com/\">Ver...  \n",
       "2  [<p>The Jeff Prosise version from MSDN magazin...  \n",
       "3  [<p>I've read somewhere the human eye can't di...  \n",
       "4  [<p>Yes, I thought about that, but I soon figu...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = questions.merge(\n",
    "    answers_grouped,\n",
    "    left_on=\"Id\",          # Question ID\n",
    "    right_on=\"QuestionId\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "questions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8278e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashut\\AppData\\Local\\Temp\\ipykernel_18420\\3468001004.py:6: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "C:\\Users\\ashut\\AppData\\Local\\Temp\\ipykernel_18420\\3468001004.py:6: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "questions[\"Clean_Title\"] = questions[\"Title\"].apply(clean_html)\n",
    "questions[\"Clean_Body\"]  = questions[\"Body\"].apply(clean_html)\n",
    "\n",
    "questions[\"Full_Text\"] = questions[\"Clean_Title\"] + \" \" + questions[\"Clean_Body\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6ab85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.to_csv(\n",
    "    \"D:/Projects/nlp_qa_platform/data/processed/stack_overflow_clean.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "407e8b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'OwnerUserId', 'CreationDate', 'ClosedDate', 'Score', 'Title',\n",
       "       'Body', 'Tags_List', 'QuestionId', 'Answers_List', 'Clean_Title',\n",
       "       'Clean_Body', 'Full_Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8b1b0e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The 'low_memory' option is not supported with the 'python' engine",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mD:/Projects/nlp_qa_platform/data/processed/stack_overflow_clean.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatin1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_bad_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mskip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# skips corrupted rows\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1607\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1604\u001b[39m \u001b[38;5;66;03m# miscellanea\u001b[39;00m\n\u001b[32m   1605\u001b[39m \u001b[38;5;28mself\u001b[39m._currow = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1607\u001b[39m options = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_options_with_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1608\u001b[39m options[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m] = kwds.get(\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1610\u001b[39m \u001b[38;5;28mself\u001b[39m.chunksize = options.pop(\u001b[33m\"\u001b[39m\u001b[33mchunksize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1660\u001b[39m, in \u001b[36mTextFileReader._get_options_with_defaults\u001b[39m\u001b[34m(self, engine)\u001b[39m\n\u001b[32m   1658\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1659\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1660\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1661\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(argname)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m option is not supported with the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1662\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(engine)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m engine\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1663\u001b[39m             )\n\u001b[32m   1664\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1665\u001b[39m     value = default\n",
      "\u001b[31mValueError\u001b[39m: The 'low_memory' option is not supported with the 'python' engine"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"D:/Projects/nlp_qa_platform/data/processed/stack_overflow_clean.csv\",\n",
    "    encoding=\"latin1\",\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\",    # skips corrupted rows\n",
    "    low_memory=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "334e4848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in d:\\projects\\nlp_qa_platform\\venv\\lib\\site-packages (22.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af93d8eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "realloc of size 2281701376 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mdata/processed\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mquestions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mD:/Projects/nlp_qa_platform/data/processed/stack_overflow_clean.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:482\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m impl = get_engine(engine)\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io.BytesIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:191\u001b[39m, in \u001b[36mPyArrowImpl.write\u001b[39m\u001b[34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m     from_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33mpreserve_index\u001b[39m\u001b[33m\"\u001b[39m] = index\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfrom_pandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df.attrs:\n\u001b[32m    194\u001b[39m     df_metadata = {\u001b[33m\"\u001b[39m\u001b[33mPANDAS_ATTRS\u001b[39m\u001b[33m\"\u001b[39m: json.dumps(df.attrs)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pyarrow\\table.pxi:4795\u001b[39m, in \u001b[36mpyarrow.lib.Table.from_pandas\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pyarrow\\pandas_compat.py:653\u001b[39m, in \u001b[36mdataframe_to_arrays\u001b[39m\u001b[34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[39m\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[32m    652\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures.Future):\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m             arrays[i] = \u001b[43mmaybe_fut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m types = [x.type \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pyarrow\\pandas_compat.py:622\u001b[39m, in \u001b[36mdataframe_to_arrays.<locals>.convert_column\u001b[39m\u001b[34m(col, field)\u001b[39m\n\u001b[32m    619\u001b[39m     type_ = field.type\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     result = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (pa.ArrowInvalid,\n\u001b[32m    624\u001b[39m         pa.ArrowNotImplementedError,\n\u001b[32m    625\u001b[39m         pa.ArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    626\u001b[39m     e.args += (\n\u001b[32m    627\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion failed for column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:365\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pyarrow\\array.pxi:91\u001b[39m, in \u001b[36mpyarrow.lib._ndarray_to_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\nlp_qa_platform\\venv\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowMemoryError\u001b[39m: realloc of size 2281701376 failed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "questions.to_parquet(\n",
    "    \"D:/Projects/nlp_qa_platform/data/processed/stack_overflow_clean.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "777bd472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(\n",
    "    n=25_000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sample_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44374231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.drop(columns=[\"Answers_List\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "950c9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "sample_df.to_parquet(\n",
    "    \"D:/Projects/nlp_qa_platform/data/processed/stack_overflow_clean.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51abae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Tags_List</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16700310</td>\n",
       "      <td>compare two excel files in a ssis \"Foreach Loo...</td>\n",
       "      <td>[sql-server, sql-server-2008, tsql, ssis]</td>\n",
       "      <td>2013-05-22T19:41:53Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11504380</td>\n",
       "      <td>Black screen appears, randomly after taking an...</td>\n",
       "      <td>[iphone, ios, uiimage, uiimagepickercontroller...</td>\n",
       "      <td>2012-07-16T12:31:16Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27754690</td>\n",
       "      <td>Java Include file to jar file I'm using Intell...</td>\n",
       "      <td>[java, intellij-idea, jar]</td>\n",
       "      <td>2015-01-03T12:08:56Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3761040</td>\n",
       "      <td>Adding a summary column to a Reporting Service...</td>\n",
       "      <td>[reporting-services]</td>\n",
       "      <td>2010-09-21T13:58:04Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37224170</td>\n",
       "      <td>When function with for loop is called it only ...</td>\n",
       "      <td>[python]</td>\n",
       "      <td>2016-05-14T07:55:53Z</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                          Full_Text  \\\n",
       "0  16700310  compare two excel files in a ssis \"Foreach Loo...   \n",
       "1  11504380  Black screen appears, randomly after taking an...   \n",
       "2  27754690  Java Include file to jar file I'm using Intell...   \n",
       "3   3761040  Adding a summary column to a Reporting Service...   \n",
       "4  37224170  When function with for loop is called it only ...   \n",
       "\n",
       "                                           Tags_List          CreationDate  \\\n",
       "0          [sql-server, sql-server-2008, tsql, ssis]  2013-05-22T19:41:53Z   \n",
       "1  [iphone, ios, uiimage, uiimagepickercontroller...  2012-07-16T12:31:16Z   \n",
       "2                         [java, intellij-idea, jar]  2015-01-03T12:08:56Z   \n",
       "3                               [reporting-services]  2010-09-21T13:58:04Z   \n",
       "4                                           [python]  2016-05-14T07:55:53Z   \n",
       "\n",
       "   Score  \n",
       "0      0  \n",
       "1      4  \n",
       "2      0  \n",
       "3      0  \n",
       "4     -2  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\n",
    "    \"D:/Projects/nlp_qa_platform/data/processed/stack_overflow_clean.csv\"\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf92b326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Tags_List</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16700310</td>\n",
       "      <td>compare two excel files in a ssis \"Foreach Loo...</td>\n",
       "      <td>[sql-server, sql-server-2008, tsql, ssis]</td>\n",
       "      <td>2013-05-22T19:41:53Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11504380</td>\n",
       "      <td>Black screen appears, randomly after taking an...</td>\n",
       "      <td>[iphone, ios, uiimage, uiimagepickercontroller...</td>\n",
       "      <td>2012-07-16T12:31:16Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27754690</td>\n",
       "      <td>Java Include file to jar file I'm using Intell...</td>\n",
       "      <td>[java, intellij-idea, jar]</td>\n",
       "      <td>2015-01-03T12:08:56Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3761040</td>\n",
       "      <td>Adding a summary column to a Reporting Service...</td>\n",
       "      <td>[reporting-services]</td>\n",
       "      <td>2010-09-21T13:58:04Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37224170</td>\n",
       "      <td>When function with for loop is called it only ...</td>\n",
       "      <td>[python]</td>\n",
       "      <td>2016-05-14T07:55:53Z</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                          Full_Text  \\\n",
       "0  16700310  compare two excel files in a ssis \"Foreach Loo...   \n",
       "1  11504380  Black screen appears, randomly after taking an...   \n",
       "2  27754690  Java Include file to jar file I'm using Intell...   \n",
       "3   3761040  Adding a summary column to a Reporting Service...   \n",
       "4  37224170  When function with for loop is called it only ...   \n",
       "\n",
       "                                           Tags_List          CreationDate  \\\n",
       "0          [sql-server, sql-server-2008, tsql, ssis]  2013-05-22T19:41:53Z   \n",
       "1  [iphone, ios, uiimage, uiimagepickercontroller...  2012-07-16T12:31:16Z   \n",
       "2                         [java, intellij-idea, jar]  2015-01-03T12:08:56Z   \n",
       "3                               [reporting-services]  2010-09-21T13:58:04Z   \n",
       "4                                           [python]  2016-05-14T07:55:53Z   \n",
       "\n",
       "   Score  \n",
       "0      0  \n",
       "1      4  \n",
       "2      0  \n",
       "3      0  \n",
       "4     -2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = [\n",
    "    \"Id\",\n",
    "    \"Full_Text\",\n",
    "    \"Tags_List\",\n",
    "    \"CreationDate\",\n",
    "    \"Score\"\n",
    "]\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02f7d777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"spaCy model loaded successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8a36226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses text for NLP models.\n",
    "    Returns a space-separated string of lemmatized tokens.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if (\n",
    "            not token.is_stop and          # remove stopwords\n",
    "            not token.is_punct and         # remove punctuation\n",
    "            token.is_alpha and             # keep only words\n",
    "            len(token.text) > 2            # remove very short tokens\n",
    "        ):\n",
    "            tokens.append(token.lemma_.lower())\n",
    "\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a41ae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [31:21<00:00, 13.29it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"Processed_Text\"] = df[\"Full_Text\"].progress_apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "147f3d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Processed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compare two excel files in a ssis \"Foreach Loo...</td>\n",
       "      <td>compare excel file ssis foreach loop container...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black screen appears, randomly after taking an...</td>\n",
       "      <td>black screen appear randomly take image tap us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java Include file to jar file I'm using Intell...</td>\n",
       "      <td>java include file jar file intellij idea devel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Full_Text  \\\n",
       "0  compare two excel files in a ssis \"Foreach Loo...   \n",
       "1  Black screen appears, randomly after taking an...   \n",
       "2  Java Include file to jar file I'm using Intell...   \n",
       "\n",
       "                                      Processed_Text  \n",
       "0  compare excel file ssis foreach loop container...  \n",
       "1  black screen appear randomly take image tap us...  \n",
       "2  java include file jar file intellij idea devel...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Full_Text\", \"Processed_Text\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "df.to_csv(\n",
    "    \"D:/Projects/nlp_qa_platform/data/processed/final_dataset.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
